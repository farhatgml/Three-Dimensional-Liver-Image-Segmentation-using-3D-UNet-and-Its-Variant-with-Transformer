{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd3I-u5ZC5fx"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_QreT9lCwbe",
        "outputId": "d1847eb2-99b0-48cc-96d6-5f517c20d755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting monai==1.2.0\n",
            "  Downloading monai-1.2.0-202306081546-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai==1.2.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai==1.2.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai==1.2.0) (1.3.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install monai==1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF3V5gcWBJY5",
        "outputId": "255cb23a-389c-4362-8442-2998f6062ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting first\n",
            "  Downloading first-2.0.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: first\n",
            "Successfully installed first-2.0.2\n"
          ]
        }
      ],
      "source": [
        "pip install first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMqE_iBhBPp5",
        "outputId": "52e858b3-e214-49d7-911c-3b69efaf8acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT3P4C3kBZ8K",
        "outputId": "ee932ce6-f05b-4baf-859a-47508afb29cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting self_attention_cv\n",
            "  Downloading self_attention_cv-1.2.3-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from self_attention_cv) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.10/dist-packages (from self_attention_cv) (0.16.0+cu121)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from self_attention_cv) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from self_attention_cv) (1.23.5)\n",
            "Requirement already satisfied: pytest>=6.2 in /usr/local/lib/python3.10/dist-packages (from self_attention_cv) (7.4.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2->self_attention_cv) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2->self_attention_cv) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2->self_attention_cv) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2->self_attention_cv) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2->self_attention_cv) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->self_attention_cv) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8->self_attention_cv) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8->self_attention_cv) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->self_attention_cv) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8->self_attention_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8->self_attention_cv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8->self_attention_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8->self_attention_cv) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->self_attention_cv) (1.3.0)\n",
            "Installing collected packages: self_attention_cv\n",
            "Successfully installed self_attention_cv-1.2.3\n"
          ]
        }
      ],
      "source": [
        "pip install self_attention_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zkq8JH8_DEwg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import first\n",
        "import einops\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        ")\n",
        "from monai.data import DataLoader, Dataset, CacheDataset\n",
        "from monai.utils import set_determinism\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.nets import SwinUNETR\n",
        "from monai.networks.layers import Norm\n",
        "from monai.losses import DiceLoss, DiceCELoss, Dice, DiceFocalLoss\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import Activations\n",
        "from monai.inferers import sliding_window_inference\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from self_attention_cv import UNETR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5t5L7urDsYS"
      },
      "outputs": [],
      "source": [
        "def prepare(in_dir, pixdim=(1.0, 1.0, 1.0), a_min=1000, a_max=1500, spatial_size=[128,128,128], cache=False):\n",
        "\n",
        "    set_determinism(seed=0)\n",
        "\n",
        "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
        "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSeg\", \"*.nii.gz\")))\n",
        "\n",
        "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
        "    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSeg\", \"*.nii.gz\")))\n",
        "\n",
        "    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
        "    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "\n",
        "    train_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max,b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if cache:\n",
        "        train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0)\n",
        "        train_loader = DataLoader(train_ds, batch_size=1)\n",
        "\n",
        "        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
        "        test_loader = DataLoader(test_ds, batch_size=1)\n",
        "\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    else:\n",
        "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
        "        train_loader = DataLoader(train_ds, batch_size=1)\n",
        "\n",
        "        test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "        test_loader = DataLoader(test_ds, batch_size=1)\n",
        "\n",
        "        return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBYOgFUfsAG_",
        "outputId": "cfbdc0a4-75ca-4179-bff2-a07d39750bb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
            "  warn_deprecated(argname, msg, warning_category)\n",
            "/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.dictionary.AddChanneld'>: Class `AddChanneld` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirstd instead with `channel_dim='no_channel'`.\n",
            "  warn_deprecated(obj, msg, warning_category)\n",
            "/usr/local/lib/python3.10/dist-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.transforms.utility.dictionary EnsureChannelFirstd.__init__:meta_keys: Argument `meta_keys` has been deprecated since version 0.9. not needed if image is type `MetaTensor`.\n",
            "  warn_deprecated(argname, msg, warning_category)\n"
          ]
        }
      ],
      "source": [
        "in_dir = '/content/drive/MyDrive/SMT 7/Internship-AIDA/128 CT scan'\n",
        "patient = prepare(in_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsYKO5lDKz2Y"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1awrqYL6F5-"
      },
      "outputs": [],
      "source": [
        "def dice_metric(predicted, target):\n",
        "    '''\n",
        "    In this function we take `predicted` and `target` (label) to calculate the dice coeficient then we use it\n",
        "    to calculate a metric value for the training and the validation.\n",
        "    '''\n",
        "    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "    value = 1 - dice_value(predicted, target).item()\n",
        "    return value\n",
        "\n",
        "def calculate_weights(val1, val2):\n",
        "    '''\n",
        "    In this function we take the number of the background and the forgroud pixels to return the `weights`\n",
        "    for the cross entropy loss values.\n",
        "    '''\n",
        "    count = np.array([val1, val2])\n",
        "    summ = count.sum()\n",
        "    weights = count/summ\n",
        "    weights = 1/weights\n",
        "    summ = weights.sum()\n",
        "    weights = weights/summ\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "def calculate_iou(predicted, target):\n",
        "    iouvalue = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True, jaccard=True)\n",
        "    iou_value = 1-iouvalue(predicted,target).item()\n",
        "    return iou_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKwD_mMd4PZb"
      },
      "outputs": [],
      "source": [
        "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1, device=torch.device(\"cuda:0\")):\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    save_loss_train = []\n",
        "    save_loss_test = []\n",
        "    save_metric_train = []\n",
        "    save_metric_test = []\n",
        "    save_iou_train = []\n",
        "    save_iou_test = []\n",
        "    train_loader, test_loader = data_in\n",
        "\n",
        "    # Initialize the ReduceLROnPlateau scheduler\n",
        "    scheduler = ReduceLROnPlateau(optim, mode='max', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "        model.train()\n",
        "        train_epoch_loss = 0\n",
        "        train_step = 0\n",
        "        epoch_metric_train = 0\n",
        "        epoch_iou_train = 0\n",
        "\n",
        "        for batch_data in train_loader:\n",
        "            train_step += 1\n",
        "            volume = batch_data[\"vol\"]\n",
        "            label = batch_data[\"seg\"]\n",
        "            label = label != 0\n",
        "            volume, label = (volume.to(device), label.to(device))\n",
        "\n",
        "            optim.zero_grad()\n",
        "            outputs = model(volume)\n",
        "\n",
        "            train_loss = loss(outputs, label)\n",
        "\n",
        "            train_loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            train_epoch_loss += train_loss.item()\n",
        "            print(f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n",
        "                  f\"Train_loss: {train_loss.item():.4f}\")\n",
        "\n",
        "            train_metric = dice_metric(outputs, label)\n",
        "            epoch_metric_train += train_metric\n",
        "            print(f'Train_dice: {train_metric:.4f}')\n",
        "\n",
        "            train_iou = calculate_iou(outputs, label)\n",
        "            epoch_iou_train += train_iou\n",
        "            print(f'Train_IoU: {train_iou:.4f}')\n",
        "\n",
        "        print('-'*20)\n",
        "\n",
        "        train_epoch_loss /= train_step\n",
        "        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n",
        "        save_loss_train.append(train_epoch_loss)\n",
        "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
        "\n",
        "        epoch_metric_train /= train_step\n",
        "        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n",
        "        save_metric_train.append(epoch_metric_train)\n",
        "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
        "\n",
        "        epoch_iou_train /= train_step\n",
        "        print(f'Epoch_IoU: {epoch_iou_train:.4f}')\n",
        "        save_iou_train.append(epoch_iou_train)\n",
        "        np.save(os.path.join(model_dir, 'iou_train.npy'), save_iou_train)\n",
        "\n",
        "        # Update the scheduler with the current epoch_metric_train\n",
        "        scheduler.step(epoch_metric_train)\n",
        "\n",
        "        if (epoch + 1) % test_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_epoch_loss = 0\n",
        "                test_metric = 0\n",
        "                epoch_metric_test = 0\n",
        "                test_step = 0\n",
        "                test_iou = 0\n",
        "                epoch_iou_test = 0\n",
        "\n",
        "                for test_data in test_loader:\n",
        "                    test_step += 1\n",
        "                    test_volume = test_data[\"vol\"]\n",
        "                    test_label = test_data[\"seg\"]\n",
        "                    test_label = test_label != 0\n",
        "                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n",
        "\n",
        "                    test_outputs = model(test_volume)\n",
        "\n",
        "                    test_loss = loss(test_outputs, test_label)\n",
        "                    test_epoch_loss += test_loss.item()\n",
        "                    test_metric = dice_metric(test_outputs, test_label)\n",
        "                    epoch_metric_test += test_metric\n",
        "                    test_iou = calculate_iou(test_outputs, test_label)\n",
        "                    epoch_iou_test += test_iou\n",
        "\n",
        "                test_epoch_loss /= test_step\n",
        "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
        "                save_loss_test.append(test_epoch_loss)\n",
        "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
        "\n",
        "                epoch_metric_test /= test_step\n",
        "                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n",
        "                save_metric_test.append(epoch_metric_test)\n",
        "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
        "\n",
        "                epoch_iou_test /= test_step\n",
        "                print(f'test_iou_epoch: {epoch_iou_test:.4f}')\n",
        "                save_iou_test.append(epoch_iou_test)\n",
        "                np.save(os.path.join(model_dir, 'iou_test.npy'), save_iou_test)\n",
        "\n",
        "                if epoch_metric_test > best_metric:\n",
        "                    best_metric = epoch_metric_test\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_model.pth\"))\n",
        "\n",
        "                print(\n",
        "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n",
        "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                    f\"at epoch: {best_metric_epoch}\"\n",
        "                )\n",
        "\n",
        "    print(\n",
        "        f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "        f\"at epoch: {best_metric_epoch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc05Pktr_8yk"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import itertools\n",
        "from collections.abc import Sequence\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "from torch.nn import LayerNorm\n",
        "\n",
        "from monai.networks.blocks import MLPBlock as Mlp\n",
        "from monai.networks.blocks import PatchEmbed, UnetOutBlock, UnetrBasicBlock, UnetrUpBlock\n",
        "from monai.networks.layers import DropPath, trunc_normal_\n",
        "from monai.utils import ensure_tuple_rep, look_up_option, optional_import\n",
        "\n",
        "rearrange, _ = optional_import(\"einops\", name=\"rearrange\")\n",
        "\n",
        "__all__ = [\n",
        "    \"SwinUNETR\",\n",
        "    \"window_partition\",\n",
        "    \"window_reverse\",\n",
        "    \"WindowAttention\",\n",
        "    \"SwinTransformerBlock\",\n",
        "    \"PatchMerging\",\n",
        "    \"PatchMergingV2\",\n",
        "    \"MERGING_MODE\",\n",
        "    \"BasicLayer\",\n",
        "    \"SwinTransformer\",\n",
        "]\n",
        "\n",
        "\n",
        "class SwinUNETR(nn.Module):\n",
        "    \"\"\"\n",
        "    Swin UNETR based on: \"Hatamizadeh et al.,\n",
        "    Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images\n",
        "    <https://arxiv.org/abs/2201.01266>\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: Sequence[int] | int,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        depths: Sequence[int] = (2, 2, 2, 2),\n",
        "        num_heads: Sequence[int] = (3, 6, 12, 24),\n",
        "        feature_size: int = 24,\n",
        "        norm_name: tuple | str = \"instance\",\n",
        "        drop_rate: float = 0.0,\n",
        "        attn_drop_rate: float = 0.0,\n",
        "        dropout_path_rate: float = 0.0,\n",
        "        normalize: bool = True,\n",
        "        use_checkpoint: bool = False,\n",
        "        spatial_dims: int = 3,\n",
        "        downsample=\"merging\",\n",
        "        use_v2=False,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_size: dimension of input image.\n",
        "            in_channels: dimension of input channels.\n",
        "            out_channels: dimension of output channels.\n",
        "            feature_size: dimension of network feature size.\n",
        "            depths: number of layers in each stage.\n",
        "            num_heads: number of attention heads.\n",
        "            norm_name: feature normalization type and arguments.\n",
        "            drop_rate: dropout rate.\n",
        "            attn_drop_rate: attention dropout rate.\n",
        "            dropout_path_rate: drop path rate.\n",
        "            normalize: normalize output intermediate features in each stage.\n",
        "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
        "            spatial_dims: number of spatial dims.\n",
        "            downsample: module used for downsampling, available options are `\"mergingv2\"`, `\"merging\"` and a\n",
        "                user-specified `nn.Module` following the API defined in :py:class:`monai.networks.nets.PatchMerging`.\n",
        "                The default is currently `\"merging\"` (the original version defined in v0.9.0).\n",
        "            use_v2: using swinunetr_v2, which adds a residual convolution block at the beggining of each swin stage.\n",
        "\n",
        "        Examples::\n",
        "\n",
        "            # for 3D single channel input with size (96,96,96), 4-channel output and feature size of 48.\n",
        "            >>> net = SwinUNETR(img_size=(96,96,96), in_channels=1, out_channels=4, feature_size=48)\n",
        "\n",
        "            # for 3D 4-channel input with size (128,128,128), 3-channel output and (2,4,2,2) layers in each stage.\n",
        "            >>> net = SwinUNETR(img_size=(128,128,128), in_channels=4, out_channels=3, depths=(2,4,2,2))\n",
        "\n",
        "            # for 2D single channel input with size (96,96), 2-channel output and gradient checkpointing.\n",
        "            >>> net = SwinUNETR(img_size=(96,96), in_channels=3, out_channels=2, use_checkpoint=True, spatial_dims=2)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        img_size = ensure_tuple_rep(img_size, spatial_dims)\n",
        "        patch_size = ensure_tuple_rep(2, spatial_dims)\n",
        "        window_size = ensure_tuple_rep(7, spatial_dims)\n",
        "\n",
        "        if spatial_dims not in (2, 3):\n",
        "            raise ValueError(\"spatial dimension should be 2 or 3.\")\n",
        "\n",
        "        for m, p in zip(img_size, patch_size):\n",
        "            for i in range(5):\n",
        "                if m % np.power(p, i + 1) != 0:\n",
        "                    raise ValueError(\"input image size (img_size) should be divisible by stage-wise image resolution.\")\n",
        "\n",
        "        if not (0 <= drop_rate <= 1):\n",
        "            raise ValueError(\"dropout rate should be between 0 and 1.\")\n",
        "\n",
        "        if not (0 <= attn_drop_rate <= 1):\n",
        "            raise ValueError(\"attention dropout rate should be between 0 and 1.\")\n",
        "\n",
        "        if not (0 <= dropout_path_rate <= 1):\n",
        "            raise ValueError(\"drop path rate should be between 0 and 1.\")\n",
        "\n",
        "        if feature_size % 12 != 0:\n",
        "            raise ValueError(\"feature_size should be divisible by 12.\")\n",
        "\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.swinViT = SwinTransformer(\n",
        "            in_chans=in_channels,\n",
        "            embed_dim=feature_size,\n",
        "            window_size=window_size,\n",
        "            patch_size=patch_size,\n",
        "            depths=depths,\n",
        "            num_heads=num_heads,\n",
        "            mlp_ratio=4.0,\n",
        "            qkv_bias=True,\n",
        "            drop_rate=drop_rate,\n",
        "            attn_drop_rate=attn_drop_rate,\n",
        "            drop_path_rate=dropout_path_rate,\n",
        "            norm_layer=nn.LayerNorm,\n",
        "            use_checkpoint=use_checkpoint,\n",
        "            spatial_dims=spatial_dims,\n",
        "            downsample=look_up_option(downsample, MERGING_MODE) if isinstance(downsample, str) else downsample,\n",
        "            use_v2=use_v2,\n",
        "        )\n",
        "\n",
        "        self.encoder1 = UnetrBasicBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=in_channels,\n",
        "            out_channels=feature_size,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.encoder2 = UnetrBasicBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=feature_size,\n",
        "            out_channels=feature_size,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.encoder3 = UnetrBasicBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=2 * feature_size,\n",
        "            out_channels=2 * feature_size,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.encoder4 = UnetrBasicBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=4 * feature_size,\n",
        "            out_channels=4 * feature_size,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.encoder10 = UnetrBasicBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=16 * feature_size,\n",
        "            out_channels=16 * feature_size,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.decoder5 = UnetrUpBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=16 * feature_size,\n",
        "            out_channels=8 * feature_size,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.decoder4 = UnetrUpBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=feature_size * 8,\n",
        "            out_channels=feature_size * 4,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.decoder3 = UnetrUpBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=feature_size * 4,\n",
        "            out_channels=feature_size * 2,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "        self.decoder2 = UnetrUpBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=feature_size * 2,\n",
        "            out_channels=feature_size,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.decoder1 = UnetrUpBlock(\n",
        "            spatial_dims=spatial_dims,\n",
        "            in_channels=feature_size,\n",
        "            out_channels=feature_size,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=True,\n",
        "        )\n",
        "\n",
        "        self.out = UnetOutBlock(spatial_dims=spatial_dims, in_channels=feature_size, out_channels=out_channels)\n",
        "\n",
        "\n",
        "    def load_from(self, weights):\n",
        "        with torch.no_grad():\n",
        "            self.swinViT.patch_embed.proj.weight.copy_(weights[\"state_dict\"][\"module.patch_embed.proj.weight\"])\n",
        "            self.swinViT.patch_embed.proj.bias.copy_(weights[\"state_dict\"][\"module.patch_embed.proj.bias\"])\n",
        "            for bname, block in self.swinViT.layers1[0].blocks.named_children():\n",
        "                block.load_from(weights, n_block=bname, layer=\"layers1\")\n",
        "            self.swinViT.layers1[0].downsample.reduction.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers1.0.downsample.reduction.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers1[0].downsample.norm.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers1.0.downsample.norm.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers1[0].downsample.norm.bias.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers1.0.downsample.norm.bias\"]\n",
        "            )\n",
        "            for bname, block in self.swinViT.layers2[0].blocks.named_children():\n",
        "                block.load_from(weights, n_block=bname, layer=\"layers2\")\n",
        "            self.swinViT.layers2[0].downsample.reduction.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers2.0.downsample.reduction.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers2[0].downsample.norm.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers2.0.downsample.norm.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers2[0].downsample.norm.bias.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers2.0.downsample.norm.bias\"]\n",
        "            )\n",
        "            for bname, block in self.swinViT.layers3[0].blocks.named_children():\n",
        "                block.load_from(weights, n_block=bname, layer=\"layers3\")\n",
        "            self.swinViT.layers3[0].downsample.reduction.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers3.0.downsample.reduction.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers3[0].downsample.norm.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers3.0.downsample.norm.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers3[0].downsample.norm.bias.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers3.0.downsample.norm.bias\"]\n",
        "            )\n",
        "            for bname, block in self.swinViT.layers4[0].blocks.named_children():\n",
        "                block.load_from(weights, n_block=bname, layer=\"layers4\")\n",
        "            self.swinViT.layers4[0].downsample.reduction.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers4.0.downsample.reduction.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers4[0].downsample.norm.weight.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers4.0.downsample.norm.weight\"]\n",
        "            )\n",
        "            self.swinViT.layers4[0].downsample.norm.bias.copy_(\n",
        "                weights[\"state_dict\"][\"module.layers4.0.downsample.norm.bias\"]\n",
        "            )\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        hidden_states_out = self.swinViT(x_in, self.normalize)\n",
        "        enc0 = self.encoder1(x_in)\n",
        "        enc1 = self.encoder2(hidden_states_out[0])\n",
        "        enc2 = self.encoder3(hidden_states_out[1])\n",
        "        enc3 = self.encoder4(hidden_states_out[2])\n",
        "        dec4 = self.encoder10(hidden_states_out[4])\n",
        "        dec3 = self.decoder5(dec4, hidden_states_out[3])\n",
        "        dec2 = self.decoder4(dec3, enc3)\n",
        "        dec1 = self.decoder3(dec2, enc2)\n",
        "        dec0 = self.decoder2(dec1, enc1)\n",
        "        out = self.decoder1(dec0, enc0)\n",
        "        logits = self.out(out)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "def window_partition(x, window_size):\n",
        "    \"\"\"window partition operation based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "\n",
        "     Args:\n",
        "        x: input tensor.\n",
        "        window_size: local window size.\n",
        "    \"\"\"\n",
        "    x_shape = x.size()\n",
        "    if len(x_shape) == 5:\n",
        "        b, d, h, w, c = x_shape\n",
        "        x = x.view(\n",
        "            b,\n",
        "            d // window_size[0],\n",
        "            window_size[0],\n",
        "            h // window_size[1],\n",
        "            window_size[1],\n",
        "            w // window_size[2],\n",
        "            window_size[2],\n",
        "            c,\n",
        "        )\n",
        "        windows = (\n",
        "            x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous().view(-1, window_size[0] * window_size[1] * window_size[2], c)\n",
        "        )\n",
        "    elif len(x_shape) == 4:\n",
        "        b, h, w, c = x.shape\n",
        "        x = x.view(b, h // window_size[0], window_size[0], w // window_size[1], window_size[1], c)\n",
        "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size[0] * window_size[1], c)\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, dims):\n",
        "    \"\"\"window reverse operation based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "\n",
        "     Args:\n",
        "        windows: windows tensor.\n",
        "        window_size: local window size.\n",
        "        dims: dimension values.\n",
        "    \"\"\"\n",
        "    if len(dims) == 4:\n",
        "        b, d, h, w = dims\n",
        "        x = windows.view(\n",
        "            b,\n",
        "            d // window_size[0],\n",
        "            h // window_size[1],\n",
        "            w // window_size[2],\n",
        "            window_size[0],\n",
        "            window_size[1],\n",
        "            window_size[2],\n",
        "            -1,\n",
        "        )\n",
        "        x = x.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous().view(b, d, h, w, -1)\n",
        "\n",
        "    elif len(dims) == 3:\n",
        "        b, h, w = dims\n",
        "        x = windows.view(b, h // window_size[0], w // window_size[1], window_size[0], window_size[1], -1)\n",
        "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(b, h, w, -1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_window_size(x_size, window_size, shift_size=None):\n",
        "    \"\"\"Computing window size based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "\n",
        "     Args:\n",
        "        x_size: input size.\n",
        "        window_size: local window size.\n",
        "        shift_size: window shifting size.\n",
        "    \"\"\"\n",
        "\n",
        "    use_window_size = list(window_size)\n",
        "    if shift_size is not None:\n",
        "        use_shift_size = list(shift_size)\n",
        "    for i in range(len(x_size)):\n",
        "        if x_size[i] <= window_size[i]:\n",
        "            use_window_size[i] = x_size[i]\n",
        "            if shift_size is not None:\n",
        "                use_shift_size[i] = 0\n",
        "\n",
        "    if shift_size is None:\n",
        "        return tuple(use_window_size)\n",
        "    else:\n",
        "        return tuple(use_window_size), tuple(use_shift_size)\n",
        "\n",
        "\n",
        "class WindowAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Window based multi-head self attention module with relative position bias based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int,\n",
        "        window_size: Sequence[int],\n",
        "        qkv_bias: bool = False,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim: number of feature channels.\n",
        "            num_heads: number of attention heads.\n",
        "            window_size: local window size.\n",
        "            qkv_bias: add a learnable bias to query, key, value.\n",
        "            attn_drop: attention dropout rate.\n",
        "            proj_drop: dropout rate of output.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim**-0.5\n",
        "        mesh_args = torch.meshgrid.__kwdefaults__\n",
        "\n",
        "        if len(self.window_size) == 3:\n",
        "            self.relative_position_bias_table = nn.Parameter(\n",
        "                torch.zeros(\n",
        "                    (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1) * (2 * self.window_size[2] - 1),\n",
        "                    num_heads,\n",
        "                )\n",
        "            )\n",
        "            coords_d = torch.arange(self.window_size[0])\n",
        "            coords_h = torch.arange(self.window_size[1])\n",
        "            coords_w = torch.arange(self.window_size[2])\n",
        "            if mesh_args is not None:\n",
        "                coords = torch.stack(torch.meshgrid(coords_d, coords_h, coords_w, indexing=\"ij\"))\n",
        "            else:\n",
        "                coords = torch.stack(torch.meshgrid(coords_d, coords_h, coords_w))\n",
        "            coords_flatten = torch.flatten(coords, 1)\n",
        "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
        "            relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "            relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "            relative_coords[:, :, 2] += self.window_size[2] - 1\n",
        "            relative_coords[:, :, 0] *= (2 * self.window_size[1] - 1) * (2 * self.window_size[2] - 1)\n",
        "            relative_coords[:, :, 1] *= 2 * self.window_size[2] - 1\n",
        "        elif len(self.window_size) == 2:\n",
        "            self.relative_position_bias_table = nn.Parameter(\n",
        "                torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)\n",
        "            )\n",
        "            coords_h = torch.arange(self.window_size[0])\n",
        "            coords_w = torch.arange(self.window_size[1])\n",
        "            if mesh_args is not None:\n",
        "                coords = torch.stack(torch.meshgrid(coords_h, coords_w, indexing=\"ij\"))\n",
        "            else:\n",
        "                coords = torch.stack(torch.meshgrid(coords_h, coords_w))\n",
        "            coords_flatten = torch.flatten(coords, 1)\n",
        "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
        "            relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "            relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "            relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "\n",
        "        relative_position_index = relative_coords.sum(-1)\n",
        "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "        trunc_normal_(self.relative_position_bias_table, std=0.02)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        b, n, c = x.shape\n",
        "        qkv = self.qkv(x).reshape(b, n, 3, self.num_heads, c // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        q = q * self.scale\n",
        "        attn = q @ k.transpose(-2, -1)\n",
        "        relative_position_bias = self.relative_position_bias_table[\n",
        "            self.relative_position_index.clone()[:n, :n].reshape(-1)  # type: ignore\n",
        "        ].reshape(n, n, -1)\n",
        "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()\n",
        "        attn = attn + relative_position_bias.unsqueeze(0)\n",
        "        if mask is not None:\n",
        "            nw = mask.shape[0]\n",
        "            attn = attn.view(b // nw, nw, self.num_heads, n, n) + mask.unsqueeze(1).unsqueeze(0)\n",
        "            attn = attn.view(-1, self.num_heads, n, n)\n",
        "            attn = self.softmax(attn)\n",
        "        else:\n",
        "            attn = self.softmax(attn)\n",
        "\n",
        "        attn = self.attn_drop(attn).to(v.dtype)\n",
        "        x = (attn @ v).transpose(1, 2).reshape(b, n, c)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SwinTransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Swin Transformer block based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int,\n",
        "        window_size: Sequence[int],\n",
        "        shift_size: Sequence[int],\n",
        "        mlp_ratio: float = 4.0,\n",
        "        qkv_bias: bool = True,\n",
        "        drop: float = 0.0,\n",
        "        attn_drop: float = 0.0,\n",
        "        drop_path: float = 0.0,\n",
        "        act_layer: str = \"GELU\",\n",
        "        norm_layer: type[LayerNorm] = nn.LayerNorm,\n",
        "        use_checkpoint: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim: number of feature channels.\n",
        "            num_heads: number of attention heads.\n",
        "            window_size: local window size.\n",
        "            shift_size: window shift size.\n",
        "            mlp_ratio: ratio of mlp hidden dim to embedding dim.\n",
        "            qkv_bias: add a learnable bias to query, key, value.\n",
        "            drop: dropout rate.\n",
        "            attn_drop: attention dropout rate.\n",
        "            drop_path: stochastic depth rate.\n",
        "            act_layer: activation layer.\n",
        "            norm_layer: normalization layer.\n",
        "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=self.window_size,\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            attn_drop=attn_drop,\n",
        "            proj_drop=drop,\n",
        "        )\n",
        "\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(hidden_size=dim, mlp_dim=mlp_hidden_dim, act=act_layer, dropout_rate=drop, dropout_mode=\"swin\")\n",
        "\n",
        "    def forward_part1(self, x, mask_matrix):\n",
        "        x_shape = x.size()\n",
        "        x = self.norm1(x)\n",
        "        if len(x_shape) == 5:\n",
        "            b, d, h, w, c = x.shape\n",
        "            window_size, shift_size = get_window_size((d, h, w), self.window_size, self.shift_size)\n",
        "            pad_l = pad_t = pad_d0 = 0\n",
        "            pad_d1 = (window_size[0] - d % window_size[0]) % window_size[0]\n",
        "            pad_b = (window_size[1] - h % window_size[1]) % window_size[1]\n",
        "            pad_r = (window_size[2] - w % window_size[2]) % window_size[2]\n",
        "            x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b, pad_d0, pad_d1))\n",
        "            _, dp, hp, wp, _ = x.shape\n",
        "            dims = [b, dp, hp, wp]\n",
        "\n",
        "        elif len(x_shape) == 4:\n",
        "            b, h, w, c = x.shape\n",
        "            window_size, shift_size = get_window_size((h, w), self.window_size, self.shift_size)\n",
        "            pad_l = pad_t = 0\n",
        "            pad_b = (window_size[0] - h % window_size[0]) % window_size[0]\n",
        "            pad_r = (window_size[1] - w % window_size[1]) % window_size[1]\n",
        "            x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b))\n",
        "            _, hp, wp, _ = x.shape\n",
        "            dims = [b, hp, wp]\n",
        "\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            if len(x_shape) == 5:\n",
        "                shifted_x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1], -shift_size[2]), dims=(1, 2, 3))\n",
        "            elif len(x_shape) == 4:\n",
        "                shifted_x = torch.roll(x, shifts=(-shift_size[0], -shift_size[1]), dims=(1, 2))\n",
        "            attn_mask = mask_matrix\n",
        "        else:\n",
        "            shifted_x = x\n",
        "            attn_mask = None\n",
        "        x_windows = window_partition(shifted_x, window_size)\n",
        "        attn_windows = self.attn(x_windows, mask=attn_mask)\n",
        "        attn_windows = attn_windows.view(-1, *(window_size + (c,)))\n",
        "        shifted_x = window_reverse(attn_windows, window_size, dims)\n",
        "        if any(i > 0 for i in shift_size):\n",
        "            if len(x_shape) == 5:\n",
        "                x = torch.roll(shifted_x, shifts=(shift_size[0], shift_size[1], shift_size[2]), dims=(1, 2, 3))\n",
        "            elif len(x_shape) == 4:\n",
        "                x = torch.roll(shifted_x, shifts=(shift_size[0], shift_size[1]), dims=(1, 2))\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        if len(x_shape) == 5:\n",
        "            if pad_d1 > 0 or pad_r > 0 or pad_b > 0:\n",
        "                x = x[:, :d, :h, :w, :].contiguous()\n",
        "        elif len(x_shape) == 4:\n",
        "            if pad_r > 0 or pad_b > 0:\n",
        "                x = x[:, :h, :w, :].contiguous()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward_part2(self, x):\n",
        "        return self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "    def load_from(self, weights, n_block, layer):\n",
        "        root = f\"module.{layer}.0.blocks.{n_block}.\"\n",
        "        block_names = [\n",
        "            \"norm1.weight\",\n",
        "            \"norm1.bias\",\n",
        "            \"attn.relative_position_bias_table\",\n",
        "            \"attn.relative_position_index\",\n",
        "            \"attn.qkv.weight\",\n",
        "            \"attn.qkv.bias\",\n",
        "            \"attn.proj.weight\",\n",
        "            \"attn.proj.bias\",\n",
        "            \"norm2.weight\",\n",
        "            \"norm2.bias\",\n",
        "            \"mlp.fc1.weight\",\n",
        "            \"mlp.fc1.bias\",\n",
        "            \"mlp.fc2.weight\",\n",
        "            \"mlp.fc2.bias\",\n",
        "        ]\n",
        "        with torch.no_grad():\n",
        "            self.norm1.weight.copy_(weights[\"state_dict\"][root + block_names[0]])\n",
        "            self.norm1.bias.copy_(weights[\"state_dict\"][root + block_names[1]])\n",
        "            self.attn.relative_position_bias_table.copy_(weights[\"state_dict\"][root + block_names[2]])\n",
        "            self.attn.relative_position_index.copy_(weights[\"state_dict\"][root + block_names[3]])  # type: ignore\n",
        "            self.attn.qkv.weight.copy_(weights[\"state_dict\"][root + block_names[4]])\n",
        "            self.attn.qkv.bias.copy_(weights[\"state_dict\"][root + block_names[5]])\n",
        "            self.attn.proj.weight.copy_(weights[\"state_dict\"][root + block_names[6]])\n",
        "            self.attn.proj.bias.copy_(weights[\"state_dict\"][root + block_names[7]])\n",
        "            self.norm2.weight.copy_(weights[\"state_dict\"][root + block_names[8]])\n",
        "            self.norm2.bias.copy_(weights[\"state_dict\"][root + block_names[9]])\n",
        "            self.mlp.linear1.weight.copy_(weights[\"state_dict\"][root + block_names[10]])\n",
        "            self.mlp.linear1.bias.copy_(weights[\"state_dict\"][root + block_names[11]])\n",
        "            self.mlp.linear2.weight.copy_(weights[\"state_dict\"][root + block_names[12]])\n",
        "            self.mlp.linear2.bias.copy_(weights[\"state_dict\"][root + block_names[13]])\n",
        "\n",
        "    def forward(self, x, mask_matrix):\n",
        "        shortcut = x\n",
        "        if self.use_checkpoint:\n",
        "            x = checkpoint.checkpoint(self.forward_part1, x, mask_matrix)\n",
        "        else:\n",
        "            x = self.forward_part1(x, mask_matrix)\n",
        "        x = shortcut + self.drop_path(x)\n",
        "        if self.use_checkpoint:\n",
        "            x = x + checkpoint.checkpoint(self.forward_part2, x)\n",
        "        else:\n",
        "            x = x + self.forward_part2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchMergingV2(nn.Module):\n",
        "    \"\"\"\n",
        "    Patch merging layer based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, norm_layer: type[LayerNorm] = nn.LayerNorm, spatial_dims: int = 3) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim: number of feature channels.\n",
        "            norm_layer: normalization layer.\n",
        "            spatial_dims: number of spatial dims.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        if spatial_dims == 3:\n",
        "            self.reduction = nn.Linear(8 * dim, 2 * dim, bias=False)\n",
        "            self.norm = norm_layer(8 * dim)\n",
        "        elif spatial_dims == 2:\n",
        "            self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
        "            self.norm = norm_layer(4 * dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_shape = x.size()\n",
        "        if len(x_shape) == 5:\n",
        "            b, d, h, w, c = x_shape\n",
        "            pad_input = (h % 2 == 1) or (w % 2 == 1) or (d % 2 == 1)\n",
        "            if pad_input:\n",
        "                x = F.pad(x, (0, 0, 0, w % 2, 0, h % 2, 0, d % 2))\n",
        "            x = torch.cat(\n",
        "                [x[:, i::2, j::2, k::2, :] for i, j, k in itertools.product(range(2), range(2), range(2))], -1\n",
        "            )\n",
        "\n",
        "        elif len(x_shape) == 4:\n",
        "            b, h, w, c = x_shape\n",
        "            pad_input = (h % 2 == 1) or (w % 2 == 1)\n",
        "            if pad_input:\n",
        "                x = F.pad(x, (0, 0, 0, w % 2, 0, h % 2))\n",
        "            x = torch.cat([x[:, j::2, i::2, :] for i, j in itertools.product(range(2), range(2))], -1)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchMerging(PatchMergingV2):\n",
        "    \"\"\"The `PatchMerging` module previously defined in v0.9.0.\"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_shape = x.size()\n",
        "        if len(x_shape) == 4:\n",
        "            return super().forward(x)\n",
        "        if len(x_shape) != 5:\n",
        "            raise ValueError(f\"expecting 5D x, got {x.shape}.\")\n",
        "        b, d, h, w, c = x_shape\n",
        "        pad_input = (h % 2 == 1) or (w % 2 == 1) or (d % 2 == 1)\n",
        "        if pad_input:\n",
        "            x = F.pad(x, (0, 0, 0, w % 2, 0, h % 2, 0, d % 2))\n",
        "        x0 = x[:, 0::2, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, 0::2, :]\n",
        "        x3 = x[:, 0::2, 0::2, 1::2, :]\n",
        "        x4 = x[:, 1::2, 0::2, 1::2, :]\n",
        "        x5 = x[:, 0::2, 1::2, 0::2, :]\n",
        "        x6 = x[:, 0::2, 0::2, 1::2, :]\n",
        "        x7 = x[:, 1::2, 1::2, 1::2, :]\n",
        "        x = torch.cat([x0, x1, x2, x3, x4, x5, x6, x7], -1)\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "MERGING_MODE = {\"merging\": PatchMerging, \"mergingv2\": PatchMergingV2}\n",
        "\n",
        "\n",
        "def compute_mask(dims, window_size, shift_size, device):\n",
        "    \"\"\"Computing region masks based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "\n",
        "     Args:\n",
        "        dims: dimension values.\n",
        "        window_size: local window size.\n",
        "        shift_size: shift size.\n",
        "        device: device.\n",
        "    \"\"\"\n",
        "\n",
        "    cnt = 0\n",
        "\n",
        "    if len(dims) == 3:\n",
        "        d, h, w = dims\n",
        "        img_mask = torch.zeros((1, d, h, w, 1), device=device)\n",
        "        for d in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0], None):\n",
        "            for h in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1], None):\n",
        "                for w in slice(-window_size[2]), slice(-window_size[2], -shift_size[2]), slice(-shift_size[2], None):\n",
        "                    img_mask[:, d, h, w, :] = cnt\n",
        "                    cnt += 1\n",
        "\n",
        "    elif len(dims) == 2:\n",
        "        h, w = dims\n",
        "        img_mask = torch.zeros((1, h, w, 1), device=device)\n",
        "        for h in slice(-window_size[0]), slice(-window_size[0], -shift_size[0]), slice(-shift_size[0], None):\n",
        "            for w in slice(-window_size[1]), slice(-window_size[1], -shift_size[1]), slice(-shift_size[1], None):\n",
        "                img_mask[:, h, w, :] = cnt\n",
        "                cnt += 1\n",
        "\n",
        "    mask_windows = window_partition(img_mask, window_size)\n",
        "    mask_windows = mask_windows.squeeze(-1)\n",
        "    attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
        "    attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
        "\n",
        "    return attn_mask\n",
        "\n",
        "\n",
        "class BasicLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic Swin Transformer layer in one stage based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        depth: int,\n",
        "        num_heads: int,\n",
        "        window_size: Sequence[int],\n",
        "        drop_path: list,\n",
        "        mlp_ratio: float = 4.0,\n",
        "        qkv_bias: bool = False,\n",
        "        drop: float = 0.0,\n",
        "        attn_drop: float = 0.0,\n",
        "        norm_layer: type[LayerNorm] = nn.LayerNorm,\n",
        "        downsample: nn.Module | None = None,\n",
        "        use_checkpoint: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim: number of feature channels.\n",
        "            depth: number of layers in each stage.\n",
        "            num_heads: number of attention heads.\n",
        "            window_size: local window size.\n",
        "            drop_path: stochastic depth rate.\n",
        "            mlp_ratio: ratio of mlp hidden dim to embedding dim.\n",
        "            qkv_bias: add a learnable bias to query, key, value.\n",
        "            drop: dropout rate.\n",
        "            attn_drop: attention dropout rate.\n",
        "            norm_layer: normalization layer.\n",
        "            downsample: an optional downsampling layer at the end of the layer.\n",
        "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = tuple(i // 2 for i in window_size)\n",
        "        self.no_shift = tuple(0 for i in window_size)\n",
        "        self.depth = depth\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                SwinTransformerBlock(\n",
        "                    dim=dim,\n",
        "                    num_heads=num_heads,\n",
        "                    window_size=self.window_size,\n",
        "                    shift_size=self.no_shift if (i % 2 == 0) else self.shift_size,\n",
        "                    mlp_ratio=mlp_ratio,\n",
        "                    qkv_bias=qkv_bias,\n",
        "                    drop=drop,\n",
        "                    attn_drop=attn_drop,\n",
        "                    drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
        "                    norm_layer=norm_layer,\n",
        "                    use_checkpoint=use_checkpoint,\n",
        "                )\n",
        "                for i in range(depth)\n",
        "            ]\n",
        "        )\n",
        "        self.downsample = downsample\n",
        "        if callable(self.downsample):\n",
        "            self.downsample = downsample(dim=dim, norm_layer=norm_layer, spatial_dims=len(self.window_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_shape = x.size()\n",
        "        if len(x_shape) == 5:\n",
        "            b, c, d, h, w = x_shape\n",
        "            window_size, shift_size = get_window_size((d, h, w), self.window_size, self.shift_size)\n",
        "            x = rearrange(x, \"b c d h w -> b d h w c\")\n",
        "            dp = int(np.ceil(d / window_size[0])) * window_size[0]\n",
        "            hp = int(np.ceil(h / window_size[1])) * window_size[1]\n",
        "            wp = int(np.ceil(w / window_size[2])) * window_size[2]\n",
        "            attn_mask = compute_mask([dp, hp, wp], window_size, shift_size, x.device)\n",
        "            for blk in self.blocks:\n",
        "                x = blk(x, attn_mask)\n",
        "            x = x.view(b, d, h, w, -1)\n",
        "            if self.downsample is not None:\n",
        "                x = self.downsample(x)\n",
        "            x = rearrange(x, \"b d h w c -> b c d h w\")\n",
        "\n",
        "        elif len(x_shape) == 4:\n",
        "            b, c, h, w = x_shape\n",
        "            window_size, shift_size = get_window_size((h, w), self.window_size, self.shift_size)\n",
        "            x = rearrange(x, \"b c h w -> b h w c\")\n",
        "            hp = int(np.ceil(h / window_size[0])) * window_size[0]\n",
        "            wp = int(np.ceil(w / window_size[1])) * window_size[1]\n",
        "            attn_mask = compute_mask([hp, wp], window_size, shift_size, x.device)\n",
        "            for blk in self.blocks:\n",
        "                x = blk(x, attn_mask)\n",
        "            x = x.view(b, h, w, -1)\n",
        "            if self.downsample is not None:\n",
        "                x = self.downsample(x)\n",
        "            x = rearrange(x, \"b h w c -> b c h w\")\n",
        "        return x\n",
        "\n",
        "\n",
        "class SwinTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Swin Transformer based on: \"Liu et al.,\n",
        "    Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\n",
        "    <https://arxiv.org/abs/2103.14030>\"\n",
        "    https://github.com/microsoft/Swin-Transformer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_chans: int,\n",
        "        embed_dim: int,\n",
        "        window_size: Sequence[int],\n",
        "        patch_size: Sequence[int],\n",
        "        depths: Sequence[int],\n",
        "        num_heads: Sequence[int],\n",
        "        mlp_ratio: float = 4.0,\n",
        "        qkv_bias: bool = True,\n",
        "        drop_rate: float = 0.0,\n",
        "        attn_drop_rate: float = 0.0,\n",
        "        drop_path_rate: float = 0.0,\n",
        "        norm_layer: type[LayerNorm] = nn.LayerNorm,\n",
        "        patch_norm: bool = False,\n",
        "        use_checkpoint: bool = False,\n",
        "        spatial_dims: int = 3,\n",
        "        downsample=\"merging\",\n",
        "        use_v2=False,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_chans: dimension of input channels.\n",
        "            embed_dim: number of linear projection output channels.\n",
        "            window_size: local window size.\n",
        "            patch_size: patch size.\n",
        "            depths: number of layers in each stage.\n",
        "            num_heads: number of attention heads.\n",
        "            mlp_ratio: ratio of mlp hidden dim to embedding dim.\n",
        "            qkv_bias: add a learnable bias to query, key, value.\n",
        "            drop_rate: dropout rate.\n",
        "            attn_drop_rate: attention dropout rate.\n",
        "            drop_path_rate: stochastic depth rate.\n",
        "            norm_layer: normalization layer.\n",
        "            patch_norm: add normalization after patch embedding.\n",
        "            use_checkpoint: use gradient checkpointing for reduced memory usage.\n",
        "            spatial_dims: spatial dimension.\n",
        "            downsample: module used for downsampling, available options are `\"mergingv2\"`, `\"merging\"` and a\n",
        "                user-specified `nn.Module` following the API defined in :py:class:`monai.networks.nets.PatchMerging`.\n",
        "                The default is currently `\"merging\"` (the original version defined in v0.9.0).\n",
        "            use_v2: using swinunetr_v2, which adds a residual convolution block at the beginning of each swin stage.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.num_layers = len(depths)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.patch_norm = patch_norm\n",
        "        self.window_size = window_size\n",
        "        self.patch_size = patch_size\n",
        "        self.patch_embed = PatchEmbed(\n",
        "            patch_size=self.patch_size,\n",
        "            in_chans=in_chans,\n",
        "            embed_dim=embed_dim,\n",
        "            norm_layer=norm_layer if self.patch_norm else None,  # type: ignore\n",
        "            spatial_dims=spatial_dims,\n",
        "        )\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
        "        self.use_v2 = use_v2\n",
        "        self.layers1 = nn.ModuleList()\n",
        "        self.layers2 = nn.ModuleList()\n",
        "        self.layers3 = nn.ModuleList()\n",
        "        self.layers4 = nn.ModuleList()\n",
        "        if self.use_v2:\n",
        "            self.layers1c = nn.ModuleList()\n",
        "            self.layers2c = nn.ModuleList()\n",
        "            self.layers3c = nn.ModuleList()\n",
        "            self.layers4c = nn.ModuleList()\n",
        "        down_sample_mod = look_up_option(downsample, MERGING_MODE) if isinstance(downsample, str) else downsample\n",
        "        for i_layer in range(self.num_layers):\n",
        "            layer = BasicLayer(\n",
        "                dim=int(embed_dim * 2**i_layer),\n",
        "                depth=depths[i_layer],\n",
        "                num_heads=num_heads[i_layer],\n",
        "                window_size=self.window_size,\n",
        "                drop_path=dpr[sum(depths[:i_layer]) : sum(depths[: i_layer + 1])],\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                drop=drop_rate,\n",
        "                attn_drop=attn_drop_rate,\n",
        "                norm_layer=norm_layer,\n",
        "                downsample=down_sample_mod,\n",
        "                use_checkpoint=use_checkpoint,\n",
        "            )\n",
        "            if i_layer == 0:\n",
        "                self.layers1.append(layer)\n",
        "            elif i_layer == 1:\n",
        "                self.layers2.append(layer)\n",
        "            elif i_layer == 2:\n",
        "                self.layers3.append(layer)\n",
        "            elif i_layer == 3:\n",
        "                self.layers4.append(layer)\n",
        "            if self.use_v2:\n",
        "                layerc = UnetrBasicBlock(\n",
        "                    spatial_dims=3,\n",
        "                    in_channels=embed_dim * 2**i_layer,\n",
        "                    out_channels=embed_dim * 2**i_layer,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    norm_name=\"instance\",\n",
        "                    res_block=True,\n",
        "                )\n",
        "                if i_layer == 0:\n",
        "                    self.layers1c.append(layerc)\n",
        "                elif i_layer == 1:\n",
        "                    self.layers2c.append(layerc)\n",
        "                elif i_layer == 2:\n",
        "                    self.layers3c.append(layerc)\n",
        "                elif i_layer == 3:\n",
        "                    self.layers4c.append(layerc)\n",
        "\n",
        "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
        "\n",
        "    def proj_out(self, x, normalize=False):\n",
        "        if normalize:\n",
        "            x_shape = x.size()\n",
        "            if len(x_shape) == 5:\n",
        "                n, ch, d, h, w = x_shape\n",
        "                x = rearrange(x, \"n c d h w -> n d h w c\")\n",
        "                x = F.layer_norm(x, [ch])\n",
        "                x = rearrange(x, \"n d h w c -> n c d h w\")\n",
        "            elif len(x_shape) == 4:\n",
        "                n, ch, h, w = x_shape\n",
        "                x = rearrange(x, \"n c h w -> n h w c\")\n",
        "                x = F.layer_norm(x, [ch])\n",
        "                x = rearrange(x, \"n h w c -> n c h w\")\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, normalize=True):\n",
        "        x0 = self.patch_embed(x)\n",
        "        x0 = self.pos_drop(x0)\n",
        "        x0_out = self.proj_out(x0, normalize)\n",
        "        if self.use_v2:\n",
        "            x0 = self.layers1c[0](x0.contiguous())\n",
        "        x1 = self.layers1[0](x0.contiguous())\n",
        "        x1_out = self.proj_out(x1, normalize)\n",
        "        if self.use_v2:\n",
        "            x1 = self.layers2c[0](x1.contiguous())\n",
        "        x2 = self.layers2[0](x1.contiguous())\n",
        "        x2_out = self.proj_out(x2, normalize)\n",
        "        if self.use_v2:\n",
        "            x2 = self.layers3c[0](x2.contiguous())\n",
        "        x3 = self.layers3[0](x2.contiguous())\n",
        "        x3_out = self.proj_out(x3, normalize)\n",
        "        if self.use_v2:\n",
        "            x3 = self.layers4c[0](x3.contiguous())\n",
        "        x4 = self.layers4[0](x3.contiguous())\n",
        "        x4_out = self.proj_out(x4, normalize)\n",
        "        return [x0_out, x1_out, x2_out, x3_out, x4_out]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bc5-T322hVb"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/SMT 7/Internship-AIDA/128 CT scan'\n",
        "model_dir = '/content/drive/MyDrive/SMT 7/Internship-AIDA/NEW results 128 Swin UNETR'\n",
        "data_in = prepare(data_dir, cache=False)\n",
        "\n",
        "roi_size=(128, 128, 128)\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = SwinUNETR(img_size=tuple(roi_size),\n",
        "                  in_channels=1,\n",
        "                  out_channels=2,\n",
        "                  drop_rate=0.1).to(device)\n",
        "\n",
        "#loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "loss_function = DiceFocalLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENAVHp8U5X55",
        "outputId": "0b95c54c-3713-4fc9-8201-f3dd5539247d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 416 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 417/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 417 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 418/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 418 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 419/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 419 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 420/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 420 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 421/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 421 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 422/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 422 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 423/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0122\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 423 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 424/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 424 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 425/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 425 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 426/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 426 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 427/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0105\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 427 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 428/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 428 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 429/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 429 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 430/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 430 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 431/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 431 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 432/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9868\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 432 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 433/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 433 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 434/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9847\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 434 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 435/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0106\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9853\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0114\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 435 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 436/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 436 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 437/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 437 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 438/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 438 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 439/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9925\n",
            "Train_IoU: 0.9851\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 439 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 440/500\n",
            "1/16, Train_loss: 0.0096\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 440 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 441/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 441 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 442/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 442 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 443/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 443 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 444/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 444 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 445/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0107\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9821\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 445 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 446/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 446 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 447/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 447 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 448/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 448 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 449/500\n",
            "1/16, Train_loss: 0.0096\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0114\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 449 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 450/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 450 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 451/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 451 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 452/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 452 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 453/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 453 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 454/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 454 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 455/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 455 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 456/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 456 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 457/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 457 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 458/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 458 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 459/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9931\n",
            "Train_IoU: 0.9864\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0114\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9839\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 459 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 460/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 460 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 461/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0122\n",
            "Train_dice: 0.9909\n",
            "Train_IoU: 0.9820\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 461 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 462/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 462 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 463/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9909\n",
            "Train_IoU: 0.9821\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 463 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 464/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9851\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 464 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 465/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 465 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 466/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0122\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9925\n",
            "Train_IoU: 0.9851\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 466 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 467/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 467 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 468/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 468 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 469/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 469 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 470/500\n",
            "1/16, Train_loss: 0.0096\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0107\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 470 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 471/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9925\n",
            "Train_IoU: 0.9851\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 471 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 472/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 472 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 473/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 473 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 474/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0114\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 474 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 475/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 475 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 476/500\n",
            "1/16, Train_loss: 0.0096\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0105\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9825\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 476 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 477/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9847\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0102\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 477 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 478/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0122\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 478 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 479/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 479 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 480/500\n",
            "1/16, Train_loss: 0.0096\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 480 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 481/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 481 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 482/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 482 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 483/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 483 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 484/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9839\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 484 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 485/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 485 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 486/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9931\n",
            "Train_IoU: 0.9864\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 486 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 487/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0105\n",
            "Train_dice: 0.9926\n",
            "Train_IoU: 0.9854\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 487 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 488/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 488 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 489/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 489 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 490/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 490 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 491/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9918\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 491 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 492/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0119\n",
            "Train_dice: 0.9911\n",
            "Train_IoU: 0.9824\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 492 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 493/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9849\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 493 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 494/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "7/16, Train_loss: 0.0110\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 494 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 495/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "3/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9861\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0112\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9841\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 495 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 496/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0088\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0090\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0092\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9844\n",
            "14/16, Train_loss: 0.0102\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9857\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 496 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 497/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9856\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0081\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9867\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0094\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9842\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 497 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 498/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9848\n",
            "2/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9837\n",
            "5/16, Train_loss: 0.0103\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0083\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "11/16, Train_loss: 0.0108\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9846\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 498 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 499/500\n",
            "1/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9841\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0122\n",
            "Train_dice: 0.9916\n",
            "Train_IoU: 0.9835\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9932\n",
            "Train_IoU: 0.9865\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0086\n",
            "Train_dice: 0.9930\n",
            "Train_IoU: 0.9862\n",
            "11/16, Train_loss: 0.0107\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9847\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9921\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0100\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9859\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0120\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9823\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 499 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "----------\n",
            "epoch 500/500\n",
            "1/16, Train_loss: 0.0097\n",
            "Train_dice: 0.9923\n",
            "Train_IoU: 0.9849\n",
            "2/16, Train_loss: 0.0098\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "3/16, Train_loss: 0.0091\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "4/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9917\n",
            "Train_IoU: 0.9836\n",
            "5/16, Train_loss: 0.0104\n",
            "Train_dice: 0.9927\n",
            "Train_IoU: 0.9855\n",
            "6/16, Train_loss: 0.0099\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "7/16, Train_loss: 0.0111\n",
            "Train_dice: 0.9924\n",
            "Train_IoU: 0.9850\n",
            "8/16, Train_loss: 0.0082\n",
            "Train_dice: 0.9933\n",
            "Train_IoU: 0.9866\n",
            "9/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "10/16, Train_loss: 0.0087\n",
            "Train_dice: 0.9929\n",
            "Train_IoU: 0.9860\n",
            "11/16, Train_loss: 0.0109\n",
            "Train_dice: 0.9922\n",
            "Train_IoU: 0.9845\n",
            "12/16, Train_loss: 0.0089\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9859\n",
            "13/16, Train_loss: 0.0093\n",
            "Train_dice: 0.9920\n",
            "Train_IoU: 0.9843\n",
            "14/16, Train_loss: 0.0101\n",
            "Train_dice: 0.9928\n",
            "Train_IoU: 0.9858\n",
            "15/16, Train_loss: 0.0113\n",
            "Train_dice: 0.9919\n",
            "Train_IoU: 0.9840\n",
            "16/16, Train_loss: 0.0121\n",
            "Train_dice: 0.9910\n",
            "Train_IoU: 0.9822\n",
            "--------------------\n",
            "Epoch_loss: 0.0100\n",
            "Epoch_metric: 0.9924\n",
            "Epoch_IoU: 0.9850\n",
            "test_loss_epoch: 0.0344\n",
            "test_dice_epoch: 0.9786\n",
            "test_iou_epoch: 0.9587\n",
            "current epoch: 500 current mean dice: 0.9750\n",
            "best mean dice: 0.9793 at epoch: 118\n",
            "train completed, best_metric: 0.9793 at epoch: 118\n"
          ]
        }
      ],
      "source": [
        "train(model, data_in, loss_function, optimizer, 500, model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVXlV73dK3bi"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuTgBG_a7rhP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpVrQWMWLHAr"
      },
      "outputs": [],
      "source": [
        "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
        "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
        "test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
        "test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))\n",
        "train_iou = np.load(os.path.join(model_dir, 'iou_train.npy'))\n",
        "test_iou = np.load(os.path.join(model_dir, 'iou_test.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "nFPBJBRWMEO4",
        "outputId": "3ed2ec9a-fd38-4fdc-a46f-879b1073066a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(\"Evaluate\", (20, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Train dice loss\")\n",
        "x = [i + 1 for i in range(len(train_loss))]\n",
        "y = train_loss\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"Train metric DICE\")\n",
        "x = [i + 1 for i in range(len(train_metric))]\n",
        "y = train_metric\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Test dice loss\")\n",
        "x = [i + 1 for i in range(len(test_loss))]\n",
        "y = test_loss\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(\"Test metric DICE\")\n",
        "x = [i + 1 for i in range(len(test_metric))]\n",
        "y = test_metric\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "inb6yILZyaVX",
        "outputId": "e742eb39-6770-4598-aa2f-cea06185d47e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training and validation dice\n",
        "plt.title(\"Training and validation DICE\")\n",
        "dice = train_metric\n",
        "val_dice = test_metric\n",
        "epochs = [i + 1 for i in range(len(train_metric))]\n",
        "plt.plot(epochs, dice, 'y', label='Training Dice')\n",
        "plt.plot(epochs, val_dice, 'r', label='Validation Dice')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Dice\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tKO7RJbJ0VvF",
        "outputId": "d7a86f46-8856-4640-815a-dc618d034752"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training and validation IOU\n",
        "plt.title(\"Training and validation IoU\")\n",
        "iou = train_iou\n",
        "val_iou = test_iou\n",
        "epochs = [i + 1 for i in range(len(train_iou))]\n",
        "plt.plot(epochs, iou, 'y', label='Training IoU')\n",
        "plt.plot(epochs, val_iou, 'r', label='Validation IoU')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dD-hUPea1k5p",
        "outputId": "a6b0231b-0d82-4039-8c0a-c7011eefb16a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training and validation dice loss\n",
        "plt.title(\"Training and validation loss\")\n",
        "loss = train_loss\n",
        "val_loss = test_loss\n",
        "epochs = [i + 1 for i in range(len(train_loss))]\n",
        "plt.plot(epochs, loss, 'y', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--eJ6xPJMVTX"
      },
      "outputs": [],
      "source": [
        "in_dir = data_dir\n",
        "path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
        "path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSeg\", \"*.nii.gz\")))\n",
        "\n",
        "path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
        "path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSeg\", \"*.nii.gz\")))\n",
        "\n",
        "#path_val_volumes = sorted(glob(os.path.join(in_dir, \"ValVolumes\", \"*.nii.gz\")))\n",
        "#path_val_segmentation = sorted(glob(os.path.join(in_dir, \"ValSeg\", \"*.nii.gz\")))\n",
        "\n",
        "train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
        "test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "test_files = test_files[3:4]\n",
        "#val_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_val_volumes, path_val_segmentation)]\n",
        "#val_files = val_files[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVb6ow3YM68j"
      },
      "outputs": [],
      "source": [
        "test_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "        AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.0,1.0,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(keys=[\"vol\"], a_min=1000, a_max=1500,b_min=0.0, b_max=1.0, clip=True),\n",
        "        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,128]),\n",
        "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO8Mb_7vNGU3"
      },
      "outputs": [],
      "source": [
        "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=1)\n",
        "\n",
        "#val_ds = Dataset(data=val_files, transform=test_transforms)\n",
        "#val_loader = DataLoader(val_ds, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vcCr8crNKPy"
      },
      "outputs": [],
      "source": [
        "roi_size=(128,128,128)\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = SwinUNETR(img_size=tuple(roi_size),\n",
        "                  in_channels=1,\n",
        "                  out_channels=2,\n",
        "                  drop_rate=0.1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb6HDWhqNOMT",
        "outputId": "8e35bbf5-0704-470f-e2d5-de12ed97c554"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SwinUNETR(\n",
              "  (swinViT): SwinTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv3d(1, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.1, inplace=False)\n",
              "    (layers1): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=24, out_features=72, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=24, out_features=24, bias=True)\n",
              "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=24, out_features=96, bias=True)\n",
              "              (linear2): Linear(in_features=96, out_features=24, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.1, inplace=False)\n",
              "              (drop2): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=192, out_features=48, bias=False)\n",
              "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers2): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
              "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
              "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.1, inplace=False)\n",
              "              (drop2): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers3): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
              "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
              "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.1, inplace=False)\n",
              "              (drop2): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
              "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers4): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "              (proj_drop): Dropout(p=0.1, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.1, inplace=False)\n",
              "              (drop2): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
              "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (encoder1): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(1, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(1, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder2): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder3): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder4): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder10): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder5): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder4): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder3): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder2): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder1): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(24, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (out): UnetOutBlock(\n",
              "    (conv): Convolution(\n",
              "      (conv): Conv3d(24, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv_8tYgqCg-u",
        "outputId": "b2dbbd0a-64cb-43e3-c077-5a52fad36c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN9MWwjJDsKU"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Assuming model is already defined\n",
        "summary(model, input_size=(1, roi_size[0], roi_size[1], roi_size[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abGIHKbyGVre",
        "outputId": "ef713d7d-9a3a-4134-e39f-27a34288084a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YrqLWUdAs1H",
        "outputId": "5506289e-2488-4022-f37b-16d397c4783f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "SwinUNETR                                               [1, 2, 128, 128, 128]     --\n",
              "├─SwinTransformer: 1-1                                  [1, 24, 64, 64, 64]       --\n",
              "│    └─PatchEmbed: 2-1                                  [1, 24, 64, 64, 64]       --\n",
              "│    │    └─Conv3d: 3-1                                 [1, 24, 64, 64, 64]       216\n",
              "│    └─Dropout: 2-2                                     [1, 24, 64, 64, 64]       --\n",
              "│    └─ModuleList: 2-3                                  --                        --\n",
              "│    │    └─BasicLayer: 3-2                             [1, 48, 32, 32, 32]       37,230\n",
              "│    └─ModuleList: 2-4                                  --                        --\n",
              "│    │    └─BasicLayer: 3-3                             [1, 96, 16, 16, 16]       120,540\n",
              "│    └─ModuleList: 2-5                                  --                        --\n",
              "│    │    └─BasicLayer: 3-4                             [1, 192, 8, 8, 8]         425,400\n",
              "│    └─ModuleList: 2-6                                  --                        --\n",
              "│    │    └─BasicLayer: 3-5                             [1, 384, 4, 4, 4]         1,588,080\n",
              "├─UnetrBasicBlock: 1-2                                  [1, 24, 128, 128, 128]    --\n",
              "│    └─UnetResBlock: 2-7                                [1, 24, 128, 128, 128]    --\n",
              "│    │    └─Convolution: 3-6                            [1, 24, 128, 128, 128]    648\n",
              "│    │    └─InstanceNorm3d: 3-7                         [1, 24, 128, 128, 128]    --\n",
              "│    │    └─LeakyReLU: 3-8                              [1, 24, 128, 128, 128]    --\n",
              "│    │    └─Convolution: 3-9                            [1, 24, 128, 128, 128]    15,552\n",
              "│    │    └─InstanceNorm3d: 3-10                        [1, 24, 128, 128, 128]    --\n",
              "│    │    └─Convolution: 3-11                           [1, 24, 128, 128, 128]    24\n",
              "│    │    └─InstanceNorm3d: 3-12                        [1, 24, 128, 128, 128]    --\n",
              "│    │    └─LeakyReLU: 3-13                             [1, 24, 128, 128, 128]    --\n",
              "├─UnetrBasicBlock: 1-3                                  [1, 24, 64, 64, 64]       --\n",
              "│    └─UnetResBlock: 2-8                                [1, 24, 64, 64, 64]       --\n",
              "│    │    └─Convolution: 3-14                           [1, 24, 64, 64, 64]       15,552\n",
              "│    │    └─InstanceNorm3d: 3-15                        [1, 24, 64, 64, 64]       --\n",
              "│    │    └─LeakyReLU: 3-16                             [1, 24, 64, 64, 64]       --\n",
              "│    │    └─Convolution: 3-17                           [1, 24, 64, 64, 64]       15,552\n",
              "│    │    └─InstanceNorm3d: 3-18                        [1, 24, 64, 64, 64]       --\n",
              "│    │    └─LeakyReLU: 3-19                             [1, 24, 64, 64, 64]       --\n",
              "├─UnetrBasicBlock: 1-4                                  [1, 48, 32, 32, 32]       --\n",
              "│    └─UnetResBlock: 2-9                                [1, 48, 32, 32, 32]       --\n",
              "│    │    └─Convolution: 3-20                           [1, 48, 32, 32, 32]       62,208\n",
              "│    │    └─InstanceNorm3d: 3-21                        [1, 48, 32, 32, 32]       --\n",
              "│    │    └─LeakyReLU: 3-22                             [1, 48, 32, 32, 32]       --\n",
              "│    │    └─Convolution: 3-23                           [1, 48, 32, 32, 32]       62,208\n",
              "│    │    └─InstanceNorm3d: 3-24                        [1, 48, 32, 32, 32]       --\n",
              "│    │    └─LeakyReLU: 3-25                             [1, 48, 32, 32, 32]       --\n",
              "├─UnetrBasicBlock: 1-5                                  [1, 96, 16, 16, 16]       --\n",
              "│    └─UnetResBlock: 2-10                               [1, 96, 16, 16, 16]       --\n",
              "│    │    └─Convolution: 3-26                           [1, 96, 16, 16, 16]       248,832\n",
              "│    │    └─InstanceNorm3d: 3-27                        [1, 96, 16, 16, 16]       --\n",
              "│    │    └─LeakyReLU: 3-28                             [1, 96, 16, 16, 16]       --\n",
              "│    │    └─Convolution: 3-29                           [1, 96, 16, 16, 16]       248,832\n",
              "│    │    └─InstanceNorm3d: 3-30                        [1, 96, 16, 16, 16]       --\n",
              "│    │    └─LeakyReLU: 3-31                             [1, 96, 16, 16, 16]       --\n",
              "├─UnetrBasicBlock: 1-6                                  [1, 384, 4, 4, 4]         --\n",
              "│    └─UnetResBlock: 2-11                               [1, 384, 4, 4, 4]         --\n",
              "│    │    └─Convolution: 3-32                           [1, 384, 4, 4, 4]         3,981,312\n",
              "│    │    └─InstanceNorm3d: 3-33                        [1, 384, 4, 4, 4]         --\n",
              "│    │    └─LeakyReLU: 3-34                             [1, 384, 4, 4, 4]         --\n",
              "│    │    └─Convolution: 3-35                           [1, 384, 4, 4, 4]         3,981,312\n",
              "│    │    └─InstanceNorm3d: 3-36                        [1, 384, 4, 4, 4]         --\n",
              "│    │    └─LeakyReLU: 3-37                             [1, 384, 4, 4, 4]         --\n",
              "├─UnetrUpBlock: 1-7                                     [1, 192, 8, 8, 8]         --\n",
              "│    └─Convolution: 2-12                                [1, 192, 8, 8, 8]         --\n",
              "│    │    └─ConvTranspose3d: 3-38                       [1, 192, 8, 8, 8]         589,824\n",
              "│    └─UnetResBlock: 2-13                               [1, 192, 8, 8, 8]         --\n",
              "│    │    └─Convolution: 3-39                           [1, 192, 8, 8, 8]         1,990,656\n",
              "│    │    └─InstanceNorm3d: 3-40                        [1, 192, 8, 8, 8]         --\n",
              "│    │    └─LeakyReLU: 3-41                             [1, 192, 8, 8, 8]         --\n",
              "│    │    └─Convolution: 3-42                           [1, 192, 8, 8, 8]         995,328\n",
              "│    │    └─InstanceNorm3d: 3-43                        [1, 192, 8, 8, 8]         --\n",
              "│    │    └─Convolution: 3-44                           [1, 192, 8, 8, 8]         73,728\n",
              "│    │    └─InstanceNorm3d: 3-45                        [1, 192, 8, 8, 8]         --\n",
              "│    │    └─LeakyReLU: 3-46                             [1, 192, 8, 8, 8]         --\n",
              "├─UnetrUpBlock: 1-8                                     [1, 96, 16, 16, 16]       --\n",
              "│    └─Convolution: 2-14                                [1, 96, 16, 16, 16]       --\n",
              "│    │    └─ConvTranspose3d: 3-47                       [1, 96, 16, 16, 16]       147,456\n",
              "│    └─UnetResBlock: 2-15                               [1, 96, 16, 16, 16]       --\n",
              "│    │    └─Convolution: 3-48                           [1, 96, 16, 16, 16]       497,664\n",
              "│    │    └─InstanceNorm3d: 3-49                        [1, 96, 16, 16, 16]       --\n",
              "│    │    └─LeakyReLU: 3-50                             [1, 96, 16, 16, 16]       --\n",
              "│    │    └─Convolution: 3-51                           [1, 96, 16, 16, 16]       248,832\n",
              "│    │    └─InstanceNorm3d: 3-52                        [1, 96, 16, 16, 16]       --\n",
              "│    │    └─Convolution: 3-53                           [1, 96, 16, 16, 16]       18,432\n",
              "│    │    └─InstanceNorm3d: 3-54                        [1, 96, 16, 16, 16]       --\n",
              "│    │    └─LeakyReLU: 3-55                             [1, 96, 16, 16, 16]       --\n",
              "├─UnetrUpBlock: 1-9                                     [1, 48, 32, 32, 32]       --\n",
              "│    └─Convolution: 2-16                                [1, 48, 32, 32, 32]       --\n",
              "│    │    └─ConvTranspose3d: 3-56                       [1, 48, 32, 32, 32]       36,864\n",
              "│    └─UnetResBlock: 2-17                               [1, 48, 32, 32, 32]       --\n",
              "│    │    └─Convolution: 3-57                           [1, 48, 32, 32, 32]       124,416\n",
              "│    │    └─InstanceNorm3d: 3-58                        [1, 48, 32, 32, 32]       --\n",
              "│    │    └─LeakyReLU: 3-59                             [1, 48, 32, 32, 32]       --\n",
              "│    │    └─Convolution: 3-60                           [1, 48, 32, 32, 32]       62,208\n",
              "│    │    └─InstanceNorm3d: 3-61                        [1, 48, 32, 32, 32]       --\n",
              "│    │    └─Convolution: 3-62                           [1, 48, 32, 32, 32]       4,608\n",
              "│    │    └─InstanceNorm3d: 3-63                        [1, 48, 32, 32, 32]       --\n",
              "│    │    └─LeakyReLU: 3-64                             [1, 48, 32, 32, 32]       --\n",
              "├─UnetrUpBlock: 1-10                                    [1, 24, 64, 64, 64]       --\n",
              "│    └─Convolution: 2-18                                [1, 24, 64, 64, 64]       --\n",
              "│    │    └─ConvTranspose3d: 3-65                       [1, 24, 64, 64, 64]       9,216\n",
              "│    └─UnetResBlock: 2-19                               [1, 24, 64, 64, 64]       --\n",
              "│    │    └─Convolution: 3-66                           [1, 24, 64, 64, 64]       31,104\n",
              "│    │    └─InstanceNorm3d: 3-67                        [1, 24, 64, 64, 64]       --\n",
              "│    │    └─LeakyReLU: 3-68                             [1, 24, 64, 64, 64]       --\n",
              "│    │    └─Convolution: 3-69                           [1, 24, 64, 64, 64]       15,552\n",
              "│    │    └─InstanceNorm3d: 3-70                        [1, 24, 64, 64, 64]       --\n",
              "│    │    └─Convolution: 3-71                           [1, 24, 64, 64, 64]       1,152\n",
              "│    │    └─InstanceNorm3d: 3-72                        [1, 24, 64, 64, 64]       --\n",
              "│    │    └─LeakyReLU: 3-73                             [1, 24, 64, 64, 64]       --\n",
              "├─UnetrUpBlock: 1-11                                    [1, 24, 128, 128, 128]    --\n",
              "│    └─Convolution: 2-20                                [1, 24, 128, 128, 128]    --\n",
              "│    │    └─ConvTranspose3d: 3-74                       [1, 24, 128, 128, 128]    4,608\n",
              "│    └─UnetResBlock: 2-21                               [1, 24, 128, 128, 128]    --\n",
              "│    │    └─Convolution: 3-75                           [1, 24, 128, 128, 128]    31,104\n",
              "│    │    └─InstanceNorm3d: 3-76                        [1, 24, 128, 128, 128]    --\n",
              "│    │    └─LeakyReLU: 3-77                             [1, 24, 128, 128, 128]    --\n",
              "│    │    └─Convolution: 3-78                           [1, 24, 128, 128, 128]    15,552\n",
              "│    │    └─InstanceNorm3d: 3-79                        [1, 24, 128, 128, 128]    --\n",
              "│    │    └─Convolution: 3-80                           [1, 24, 128, 128, 128]    1,152\n",
              "│    │    └─InstanceNorm3d: 3-81                        [1, 24, 128, 128, 128]    --\n",
              "│    │    └─LeakyReLU: 3-82                             [1, 24, 128, 128, 128]    --\n",
              "├─UnetOutBlock: 1-12                                    [1, 2, 128, 128, 128]     --\n",
              "│    └─Convolution: 2-22                                [1, 2, 128, 128, 128]     --\n",
              "│    │    └─Conv3d: 3-83                                [1, 2, 128, 128, 128]     50\n",
              "=========================================================================================================\n",
              "Total params: 15,703,004\n",
              "Trainable params: 15,703,004\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 186.93\n",
              "=========================================================================================================\n",
              "Input size (MB): 8.39\n",
              "Forward/backward pass size (MB): 5070.95\n",
              "Params size (MB): 62.02\n",
              "Estimated Total Size (MB): 5141.36\n",
              "========================================================================================================="
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchinfo import summary\n",
        "\n",
        "# Create a dummy input with 1 channel for PatchEmbed\n",
        "dummy_input = torch.randn((1, 1, roi_size[0], roi_size[1], roi_size[2])).to(\"cuda\")\n",
        "\n",
        "# Use torchinfo to print the summary\n",
        "summary(model, input_data=dummy_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5jgQ48uNax7"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    Activations,\n",
        ")\n",
        "from monai.inferers import sliding_window_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmiGsqYLNPtp"
      },
      "outputs": [],
      "source": [
        "sw_batch_size = 4\n",
        "roi_size = (128, 128, 128)\n",
        "with torch.no_grad():\n",
        "    test_patient = first(test_loader) #\n",
        "    t_volume = test_patient['vol']\n",
        "    #t_segmentation = test_patient['seg']\n",
        "\n",
        "    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "    sigmoid_activation = Activations(sigmoid=True)\n",
        "    test_outputs = sigmoid_activation(test_outputs)\n",
        "    test_outputs = test_outputs > 0.5\n",
        "\n",
        "    for i in range(128):\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0, cmap='gray')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i], cmap='gray')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfSsJ3oj7F3t",
        "outputId": "c98029bf-233e-4562-cd3b-873e89c7c90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Volume shape: torch.Size([1, 1, 128, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "print(\"Volume shape:\", t_volume.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jw9hrw-F0Mkp",
        "outputId": "86a928e6-6932-4572-bbea-0e18ee02dc3a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.transforms import Activations\n",
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "\n",
        "sw_batch_size = 4\n",
        "roi_size = (128, 128, 128)\n",
        "\n",
        "# Get a sample from the test_loader\n",
        "with torch.no_grad():\n",
        "    test_patient = next(iter(test_loader))\n",
        "    t_volume = test_patient['vol'].to(device)\n",
        "\n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Inference\n",
        "    test_outputs = sliding_window_inference(t_volume, roi_size, sw_batch_size, model)\n",
        "    sigmoid_activation = Activations(sigmoid=True)\n",
        "    test_outputs = sigmoid_activation(test_outputs)\n",
        "    test_outputs = test_outputs > 0.5\n",
        "\n",
        "    # Measure elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Inference time: {elapsed_time} seconds\")\n",
        "\n",
        "    # Visualization\n",
        "    for i in range(128):\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0, cmap='gray')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i], cmap='gray')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmZLqukPWoQu",
        "outputId": "90efc2f3-a029-4e86-b989-8681ac689f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Test Loss: 0.0313\n",
            "Final Test Dice: 0.9793\n",
            "Final Test IoU: 0.9601\n"
          ]
        }
      ],
      "source": [
        "# Load the best model checkpoint\n",
        "best_model_path = os.path.join(model_dir, \"best_metric_model.pth\")\n",
        "best_model = model.to(device)\n",
        "best_model.load_state_dict(torch.load(best_model_path))\n",
        "best_model.eval()\n",
        "\n",
        "def evaluate(model, dataloader, loss_function, device=torch.device(\"cuda:0\")):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_metric = 0.0\n",
        "    total_iou = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data in dataloader:\n",
        "            inputs = batch_data[\"vol\"].to(device)\n",
        "            labels = batch_data[\"seg\"].to(device)\n",
        "            labels = labels != 0  # Assuming binary segmentation\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Compute your evaluation metric (e.g., dice coefficient)\n",
        "            metric = dice_metric(outputs, labels)\n",
        "            total_metric += metric\n",
        "\n",
        "            # Compute IoU\n",
        "            iou = calculate_iou(outputs, labels)\n",
        "            total_iou += iou\n",
        "\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "    average_loss = total_loss / total_samples\n",
        "    average_metric = total_metric / total_samples\n",
        "    average_iou = total_iou / total_samples\n",
        "\n",
        "    return average_loss, average_metric, average_iou\n",
        "\n",
        "# Evaluate the best model on your test data\n",
        "final_test_loss, final_test_metric, final_test_iou = evaluate(best_model, test_loader, loss_function, device)\n",
        "\n",
        "# Print the final metrics\n",
        "print(f\"Final Test Loss: {final_test_loss:.4f}\")\n",
        "print(f\"Final Test Dice: {final_test_metric:.4f}\")\n",
        "print(f\"Final Test IoU: {final_test_iou:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "CReYQCKpIVDl",
        "outputId": "0fddf188-d161-428b-a5c8-b6264d7749e9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "sw_batch_size = 4\n",
        "roi_size = (128, 128, 128)\n",
        "\n",
        "with torch.no_grad(), autocast():\n",
        "    test_patient = first(test_loader) #\n",
        "    t_volume = test_patient['vol']\n",
        "    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "    sigmoid_activation = Activations(sigmoid=True)\n",
        "    test_outputs = sigmoid_activation(test_outputs)\n",
        "    test_outputs = test_outputs > 0.5\n",
        "\n",
        "    # Convert boolean array to integer array for prediction\n",
        "    prediction_array = test_outputs[0, 1].detach().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "    # Convert original mask values to binary mask (0 or 1)\n",
        "    label_array = (test_patient['seg'][0, 0].detach().cpu().numpy() > 0).astype(np.uint8)\n",
        "\n",
        "    # Save the prediction and label as Nifti\n",
        "    output_nifti_pred = nib.Nifti1Image(prediction_array, affine=np.eye(4))\n",
        "    output_nifti_label = nib.Nifti1Image(label_array, affine=np.eye(4))\n",
        "\n",
        "    nib.save(output_nifti_pred, 'NEW_FIX_SWIN29PREDICT.nii.gz')\n",
        "    #nib.save(output_nifti_label, 'label_19.nii.gz')\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Example visualization for prediction\n",
        "    plt.imshow(prediction_array[:, :, 80], cmap='gray')\n",
        "    plt.title('Prediction')\n",
        "    plt.show()\n",
        "\n",
        "    # Example visualization for label with 'binary' colormap\n",
        "    plt.imshow(label_array[:, :, 80], cmap='gray')\n",
        "    plt.title('Label')\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
